{
  "hash": "ea885cea37578b2228bfe4b54032e024",
  "result": {
    "markdown": "---\ntitle: \"Image analysis\"\n---\n\n\n::: {.callout-note appearance=\"simple\"}\nThis is a work in progress that is currently undergoing heavy technical editing and copy-editing\n:::\n\n## The actual severity measure\n\nAmong the different ways to express plant disease severity, the percent area affected (symptomatic) by the disease is one of the most common especially when dealing with diseases that affect leaves. To evaluate whether the visual estimates of plant disease severity are sufficiently accurate (as seen in the previous chapter), one needs the actual severity values. These are also needed when preparing standard area diagrams (SADs) which are diagrammatic representations of severity values used as an aid prior or during the visual assessment to standardize and produce more accurate results across different raters [@delponte2017].\n\nThe actual severity values are usually approximated using image analysis where the image is segmented and each pixel of the image is labeled according to three different classes:\n\n1.  Diseased (or symptomatic)\n2.  Non-diseased (or healthy)\n3.  Background (the non-plant portion of the image)\n\nThe ratio between the diseased area and total area of the unit (e.g. the whole plant organ or section image) gives the proportion of diseased area or the percent area affected (when multiplied by 100). Several different proprietary or open-source software has been used by researchers to determine the actual severity according to a review on standard area diagrams [@delponte2017].\n\nHere, we will use the `measure_disease()` function of the *pliman* (Plant IMage ANalysis) [@olivoto2022a] R package to measures percent area affected. The package was compared with other software for determining plant disease severity on five different plant diseases and showed to produce accurate results for most of the cases [@olivoto2022].\n\nThere are basically two methods to measure severity. The first is based on image palettes that define each class of the image. The second is based on RGB-based indices [@alves2021]. Let's see the first method and also one interactive way of setting the color palettes.\n\n## Image palettes\n\nThe most critical is the initial step, when the user needs to correctly define the color palettes for each class. In *pliman* the palettes are actually separate images representing each of three classes named background (b), symptomatic (s) and healthy (h).\n\nThe reference image palettes can be constructed by manually sampling small areas of the image and producing a composite image. Of course, the results may vary depending on how these areas are chosen. A work on the validation of the *pliman* to determine disease severity showed the effect of different palettes prepared independently by three researchers [@olivoto2022]. The observation of the processed masks during the calibration of the palettes is important to create reference palettes that are most representative of the respective class.\n\nHere, I cut and pasted several sections of images representative of each class from a few leaves into a Google slide. Once the image palette was ready, I exported each one as a separate image PNG file (JPG also works). These were named: sbr_b.png, sbr_h.png and sbr_s.png. They can be found [here in this folder](https://github.com/emdelponte/epidemiology-R/tree/main/imgs) for downloading.\n\n[![Preparation of image palettes by manually sampling fraction of the images that represent background, heatlhy leaf and lesions](imgs/pliman1.png){#fig-pliman1 style=\"margin: 15px\" fig-align=\"center\"}](Fig_palettes)\n\nNow that we have the image palettes, we need to import them into the environment, using `image_import()` function for further analysis. Let's create an image object for each palette named h (healthy), s (symptoms) and b (background).\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-1_b598b97d359cac503ca53b51504aa206'}\n\n```{.r .cell-code}\nlibrary(pliman)\nh <- image_import(\"imgs/sbr_h.png\")\ns <- image_import(\"imgs/sbr_s.png\")\nb <- image_import(\"imgs/sbr_b.png\")\n```\n:::\n\n\nWe can visualize the imported image palettes using the `image_combine()` function.\n\n\n::: {.cell hash='data-actual-severity_cache/html/fig-palettes_d4183d2ef6b41ac34c7060309e0ecdb0'}\n\n```{.r .cell-code}\nimage_combine(h, s, b, ncol =3)\n```\n\n::: {.cell-output-display}\n![Image palettes created to segment images into background, sypomtoms and healthy area of the image](data-actual-severity_files/figure-html/fig-palettes-1.png){#fig-palettes width=672}\n:::\n:::\n\n\n## Measuring severity\n\n### Single image\n\nTo determine severity in a single image (e.g. img46.png), the image file needs to be loaded and assigned to an object using the same `image_import()` function used to load the palettes. We can then visualize the image, again using `image_combine()`.\n\n::: callout-tip\nThe collection of images used in this chapter can be found [here](https://github.com/emdelponte/epidemiology-R/tree/main/imgs/originals).\n:::\n\n\n::: {.cell hash='data-actual-severity_cache/html/fig-img_e87c623f9a26c3acce6b42891c64591b'}\n\n```{.r .cell-code}\nimg <- image_import(\"imgs/originals/img46.png\")\nimage_combine(img)\n```\n\n::: {.cell-output-display}\n![Imported image for further analysis](data-actual-severity_files/figure-html/fig-img-1.png){#fig-img width=672}\n:::\n:::\n\n\nNow the fun begins with the `measure_disease()` function. Four arguments are needed when using the reference image palettes, the one representing the target image and each of the three images of the color palettes. As the author of the package says \"pliman will take care of all details!\". The severity is the value shown under symptomatic in the output.\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-4_afa4ea29c8bf7dc2a61276ebd3fbe2cf'}\n\n```{.r .cell-code}\nset.seed(123)\nmeasure_disease(\n  img = img,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = TRUE\n)\n```\n\n::: {.cell-output-display}\n![](data-actual-severity_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n$severity\n   healthy symptomatic\n1 92.68302    7.316983\n\n$shape\nNULL\n\n$statistics\nNULL\n\nattr(,\"class\")\n[1] \"plm_disease\"\n```\n:::\n:::\n\n\n### Multiple images\n\nMeasuring severity in single images is fun, but usually we don't have a single image to process but several. It would take a longer time to process each one using the above procedure, thus becoming tedious.\n\nTo automate the process, *pliman* offers a batch processing approach. For such, instead of using `img` argument, one can use `pattern` and define the prefix of names of the images. In addition, we also need to define the folder where the original files are located.\n\nIf the users wants to save the processed masks, the `save_image` argument needs to be set to TRUE and the directory where the images will be saved also should be informed. Check below how to process 10 images of soybean rust symptoms. The outcome is a `list` object with the measures of the percent healthy and percent symptomatic area for each leaf in the `severity` object.\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-5_33ccfc7dbe31f5a8bd65fd3b744fe358'}\n\n```{.r .cell-code}\npliman <- measure_disease(\n  pattern = \"img\",\n  dir_original = \"imgs/originals\" ,\n  dir_processed = \"imgs/processed\",\n  save_image = TRUE,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img11 |====                                     | 10% 00:00:00 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img35 |========                                 | 20% 00:00:02 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img37 |============                             | 30% 00:00:03 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img38 |================                         | 40% 00:00:03 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img46 |====================                     | 50% 00:00:04 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img5 |=========================                 | 60% 00:00:06 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img63 |=============================            | 70% 00:00:08 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img67 |=================================        | 80% 00:00:09 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img70 |=====================================    | 90% 00:00:11 \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing image img75 |=========================================| 100% 00:00:12 \n```\n:::\n\n```{.r .cell-code}\nseverity <- pliman$severity\nseverity\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     img  healthy symptomatic\n1  img11 70.80072  29.1992835\n2  img35 46.96430  53.0357002\n3  img37 60.49390  39.5060986\n4  img38 79.14737  20.8526306\n5  img46 93.15143   6.8485680\n6   img5 20.53977  79.4602312\n7  img63 97.15698   2.8430190\n8  img67 99.83723   0.1627709\n9  img70 35.58683  64.4131683\n10 img75 93.04517   6.9548329\n```\n:::\n:::\n\n\nWith the argument `save_image` set to TRUE, the images are all saved in the folder with the standard prefix \"proc.\"\n\n[![Images created by pliman and exported to a specific folder](imgs/pliman2.png){#fig-pliman2 style=\"margin: 15px\" fig-align=\"center\"}](fig_folder)\n\nLet's have a look at one of the processed images.\n\n[![Figure created by pliman after batch processing to segment the images and calculate percent area covered by symptoms. The symptomatic area is delinated in the image.](imgs/processed/proc_img46.jpg){#fig-processed style=\"margin: 15px\" fig-align=\"center\" width=\"452\"}](fig_proc1)\n\n## How good are these measurements?\n\nThese 10 images were previously processed in QUANT software for measuring severity which is also based on image threshold. Let's create a tibble for the image code and respective \"actual\" severity - assuming QUANT measures as reference.\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-6_c48e27f95b2b90a50c2c17cd92cdfca1'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nquant <- tribble(\n  ~img, ~actual,\n   \"img5\",     75,\n  \"img11\",     24,\n  \"img35\",     52,\n  \"img37\",     38,\n  \"img38\",     17,\n  \"img46\",      7,\n  \"img63\",    2.5,\n  \"img67\",   0.25,\n  \"img70\",     67,\n  \"img75\",     10\n  )\n```\n:::\n\n\nWe can now combine the two dataframes and produce a scatter plot relating the two measures.\n\n\n::: {.cell hash='data-actual-severity_cache/html/fig-scatter_b65bbd2056d15b3f82b69ee9e8cf26f8'}\n\n```{.r .cell-code}\ndat <- left_join(severity, quant)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining, by = \"img\"\n```\n:::\n\n```{.r .cell-code}\ndat %>%\n  ggplot(aes(actual, symptomatic)) +\n  geom_point(size = 5, shape = 16, color = \"gray50\") +\n  ylim(0, 100) +\n  xlim(0, 100) +\n  geom_abline(slope = 1, intercept = 0) +\n  theme_light() +\n  labs(x = \"Quant\",\n       y = \"pliman\")\n```\n\n::: {.cell-output-display}\n![Scatter plot for the relationship between severity values measured by pliman and Quant software](data-actual-severity_files/figure-html/fig-scatter-1.png){#fig-scatter width=672}\n:::\n:::\n\n\nThe concordance correlation coefficient is a test for agreement between two observers or two methods (see previous chapter). It is an indication of how accurate the *pliman* measures are compared with a standard. The coefficient is greater than 0.99 (1.0 is perfect concordance), suggesting an excellent agreement!\n\n\n::: {.cell hash='data-actual-severity_cache/html/unnamed-chunk-8_ae361bd07a4c75acc60a044b3c0658de'}\n\n```{.r .cell-code}\nlibrary(epiR)\nccc <- epi.ccc(dat$actual, dat$symptomatic)\nccc$rho.c\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n        est     lower     upper\n1 0.9940941 0.9774812 0.9984606\n```\n:::\n:::\n\n\nIn conclusion, the most critical step, as mentioned, is the definition of the reference image palettes. A few preliminary runs may be needed for a few images to check whether the segmentation is being performed correctly, based on visual judgement. This is no different than any other color-threshold based methods when the choices made by the user affect the final result and contribute to variation among assessors. The cons are the same encountered in the direct competitors, which is the necessity to have images obtained at uniform and controlled conditions, especially a contrasting background.\n\n## Creating palettes interactively\n\nPliman offers another function `measure_disease_iter()` which allows the user to pick up samples in the image to create the color palettes for each required clss (background, healthy and symptoms). Check the video below!\n\n\n{{< video https://www.youtube.com/embed/fI_Mm-GlPyw >}}\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}