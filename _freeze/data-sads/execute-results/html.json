{
  "hash": "a8586214b3220bcb4cef0b29408f17d6",
  "result": {
    "markdown": "---\ntitle: \"Standard area diagrams\"\neditor_options: \n  chunk_output_type: inline\n---\n\n\n::: {.callout-note appearance=\"simple\"}\nThis is a work in progress that is currently undergoing heavy technical editing and copy-editing\n:::\n\n## Definitions\n\nAccording to a glossary on phytopathometry [@bock2021], standard area diagram (SAD) can be defined as \"*a generic term for a pictorial or graphic representation (drawing or true-color photo) of selected disease severities on plants or plant parts (leaves, fruit, flowers, etc.) generally used as an aid for more accurate visual estimation (on the percentage scale) or classification (using an ordinal scale) of severity on a specimen\".*\n\nThe SADs, also known as diagrammatic scales, are a set of diagrams which have long use in plant pathology. The tool dates back to the late 1800s, when the Cobb scale was developed with five diagrams illustrating a range of severity values of rust pustules on wheat leaves.\n\nIn the last 20 years, plant pathologists have taken advantage of advances in image processing and analysis tools and from knowledge gained from the psychophysical and measurement sciences to develop SADs that are realistic (e.g. true color photographs), with appropriate validation and illustrated severities to maximize estimation accuracy. SADs have been designed in various color types (black or white, two-color or true-color) and and incremental scales (approximated linear or logarithmic) [@delponte2017].\n\nThe SADs have proven useful to increase accuracy of the visual estimates as the estimation of percentage areas is deemed more challenging than classification of severity into [ordinal classes](data-ordinal.html) - there is a large number of options to choose from on the percentage scale, compared to the finite and small number of classes in ordinal scales. A recent quantitative review confirmed that the use of SADs most often results in improved accuracy and precision of visual estimates, but identified factors related to SAD design and structure, disease symptoms, and actual severity that affected the results. In particular, the SADs have proven greater utility for raters that inherently less accurate and diseases characterized by small and numerous lesions [@delponte2022]. Follows examples of SADs in black and white, two-color and true-color:\n\n------------------------------------------------------------------------\n\n![Actual photos of symptoms of loquat scab on fruit (left) and a SADs with eight diagrams (right). Each number represents severity as the percent area affected [@gonzález-domínguez2014]](imgs/sad-loquat.png){#fig-sad-loquat fig-align=\"center\" width=\"625\"}\n\n------------------------------------------------------------------------\n\n![SADs for Glomerella leaf spot on apple leaf. Each number represents severity as the percent area affected [@moreira2018]](imgs/sad-apple.png){#fig-sad-apple fig-align=\"center\" width=\"622\"}\n\n------------------------------------------------------------------------\n\n![SADs for soybean rust. Each number represents severity as the percent area affected [@franceschi2020]](imgs/sad-sbr.png){#fig-sad-sbr fig-align=\"center\" width=\"625\"}\n\nMore SADs can be found in the [SADBank](https://emdelponte.github.io/sadbank/), a curated collection of articles on SAD development and validation. Click on the image below to get access to the database.\n\n[![SADBank, a curated collection of articles](imgs/sadbank.png){#fig-sadbank fig-align=\"center\" width=\"87%\"}](https://emdelponte.github.io/sadbank/)\n\n## SAD development and validation\n\nA systematic review of the literature on SADs highlighted the most important aspects related with the development and validation of the tool [@delponte2017]. A list of best practices was proposed in the review to guide future research in the area. Follows the most important aspects to be noted:\n\n::: callout-tip\n## Best practices on SADs development\n\n-   Sample a minimum number (e.g., n = 100) of specimens from natural epidemics representing the range of disease severity and typical symptoms observed.\n\n-   Use reliable image analysis software to discriminate disease symptoms from healthy areas to calculate percent area affected.\n\n-   When designing the illustrations for the SAD set, ensure that the individual diagrams are prepared realistically, whether line drawn, actual photos, or computer generated.\n\n-   The number of diagrams should be no less than 6 and no more than 10, distributed approximately linearly, and spaced no more than 15% apart. Additional diagrams (±2) should be included between 0 and 10% severity.\n\n-   For the validation trial, select at least 50 specimens representing the full range of actual severity and symptom patterns.\n\n-   When selecting raters (a minimum of 15) for validation, make sure they do not have previous experience in using the SAD under evaluation.\n\n-   Provide standard instructions on how to recognize the symptoms of the disease and how to assess severity, first without and then with the SAD.\n\n-   Ideally repeat the assessment in time, with a 1- or 2-week interval, both without and with the aid, using the same set of raters in order to evaluate the effect of training and experience on gains in accuracy.\n\n-   Both pre- and posttest experiment conditions should be the same to avoid any impact of distraction on accuracy of estimates during the tests.\n:::\n\n## Designing SADs in R\n\nThe diagrams used in the set have been designed using several methods and technology, ranging from hand drawing to actual photos [@delponte2017]. There is an increasing tendency to use actual photos that are analysed digitally, using standard image analysis software, to determine the percent area affected. In this approach, a large set of images is analyzed and some images are chosen to represent the severities of the SAD according to the scale structure.\n\nIn R, the pliman package has a function called `sad()` which allows the automatic generation of a SADs with a pre-defined number of diagrams. Firstly, as shown in the [previous chapter](data-actual-severity.html), the set of images to be selected needs to be analysed using the `measure_disease()` function. Then, a SADs is automatically generated. In the function, the specimens with the smallest and highest severity will be selected for the SAD. The intermediate diagrams are sampled sequentially to achieve the pre-defined number of images after the severity has been ordered from low to high. More details of the function [here](https://tiagoolivoto.github.io/pliman/reference/sad.html).\n\nLet's use the [same set](data-actual-severity.html#multiple-images) of 10 soybean leaves, as seen in the previous chapter, depicting the rust symptoms and create the `sbr` object.\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-1_2f85320114b39ae444e3bc0d9021a5f8'}\n\n```{.r .cell-code}\nlibrary(pliman)\nh <- image_import(\"imgs/sbr_h.png\")\ns <- image_import(\"imgs/sbr_s.png\")\nb <- image_import(\"imgs/sbr_b.png\")\n\nsbr <- measure_disease(\n  pattern = \"img\",\n  dir_original = \"imgs/originals\" ,\n  dir_processed = \"imgs/processed\",\n  save_image = TRUE,\n  img_healthy = h,\n  img_symptoms = s,\n  img_background = b,\n  show_image = FALSE,\n  show_original = FALSE, # set to TRUE for showing the original.\n  col_background = \"white\", \n  verbose = FALSE\n)\n```\n:::\n\n\nWe are ready to run the `sad()` function to create a SADs with five diagrams side by side. The resulting SADs is in two-color as standard. Set the argument `show_original` to `TRUE` for showing the orignal image in the SADs.\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-2_fe66ce8e7eee82d0a2a1ffc7d734bdd1'}\n\n```{.r .cell-code}\nsad(sbr, 5, ncol = 5)\n```\n\n::: {.cell-output-display}\n![](data-sads_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n    img  healthy symptomatic rank\n8 img67 99.84530   0.1547021    1\n5 img46 92.65801   7.3419891    3\n4 img38 80.48860  19.5114030    5\n3 img37 59.85029  40.1497100    7\n6  img5 21.02512  78.9748781   10\n```\n:::\n:::\n\n\n## Analysis of SADs validation data\n\nTo evaluate the effect of SAD on accuracy components, analyze the data, preferably using concordance analysis methods ([see chapter](data-accuracy.html)), to fully explore which component is affected and to gain insight into the ramification of errors. Linear regression should not be used as the sole method but it could be complementary for comparison with previous literature.\n\nInferential methods should be used for testing hypotheses related to gain in accuracy. If parametric tests are used (paired t-test for example), make sure to check that the assumptions are not violated. Alternatively, nonparametric tests (Wilcoxon signed rank) or nonparametric bootstrapping should be used when the conditions for parametric tests are not met. More recently, a (parametric) mixed modelling framework has been used to analyse SADs validation data where raters are taken as a random effects in the model [@gonzález-domínguez2014; @franceschi2020; @pereira2020].\n\n### Non parametric boostrapping of differences\n\nBootstrap is a resampling method where large numbers of samples of the same size are repeatedly drawn, ***with replacement***, from a single original sample. It is commonly used when thedistribution of a statistic is unknown or complicated and the sample size is too small to draw a valid inference.\n\nA bootstrap-based equivalence test procedure was first proposed as complementary to parametric (paired t-test) or non-parametric (Wilcoxon) to analyze severity estimation data in a study on the development and validation of a SADs for pecan scab [@yadav2012]. The equivalence test was used to calculate 95% confidence intervals (CIs) for each statistic by bootstrapping using the percentile method (with an equivalence test, the null hypothesis is the converse of H0, i.e. the null hypothesis is non-equivalence). In that study, the test was used to compare means of the CCC statistics across raters under two conditions: 1) without versus with the SAD; and 2) experienced versus inexperienced raters.\n\nTo apply the bootstrap-based equivalence test, let's work with the CCC data for a sample of 20 raters who estimated severity of soybean rust SAD first without and then with the aid. The CCC was calculated as shown [here](data-accuracy.html#concordance-correlation-coefficient).\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-3_36da63bf0d4f867789443cd8b5a4cda3'}\n\n```{.r .cell-code}\nsbr <- tibble::tribble(\n  ~rater, ~aided, ~unaided,\n      1L,   0.97,     0.85,\n      2L,   0.97,     0.85,\n      3L,   0.95,     0.82,\n      4L,   0.93,     0.69,\n      5L,   0.97,     0.84,\n      6L,   0.96,     0.86,\n      7L,   0.98,     0.78,\n      8L,   0.93,     0.72,\n      9L,   0.94,     0.67,\n     10L,   0.95,     0.53,\n     11L,   0.94,     0.78,\n     12L,   0.98,     0.89,\n     13L,   0.96,      0.8,\n     14L,   0.98,     0.87,\n     15L,   0.98,      0.9,\n     16L,   0.98,     0.87,\n     17L,   0.98,     0.84,\n     18L,   0.97,     0.86,\n     19L,   0.98,     0.89,\n     20L,   0.98,     0.78\n  )\n```\n:::\n\n\nLet's visualize the data using boxplots. Each point in the plot represents a rater.\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-4_19a61c6fd64fcd6aca3708da0550e260'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ntheme_set(theme_bw(base_size = 16))\nsbr |> \n  pivot_longer(2:3, names_to = \"condition\", values_to =\"estimate\") |> \n  ggplot(aes(condition, estimate))+\n  geom_boxplot(outlier.colour = NA)+\n  geom_jitter(width = 0.05, size = 2, alpha = 0.5)+\n  ylim(0.4,1)\n```\n\n::: {.cell-output-display}\n![](data-sads_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nWe now need to create a variable for the difference of the means of the estimates (aided minus unaided) prior to bootstrapping this difference using two specialized packages. If the 95% CI does not include zero, this means that there was a significant improvement in the statistics.\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-5_34928aebc1c55d8bc03412a0d93a32e2'}\n\n```{.r .cell-code}\n# diff of means\nsbr$diff <- sbr$aided - sbr$unaided\n\nsbr$diff\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.12 0.12 0.13 0.24 0.13 0.10 0.20 0.21 0.27 0.42 0.16 0.09 0.16 0.11 0.08\n[16] 0.11 0.14 0.11 0.09 0.20\n```\n:::\n\n```{.r .cell-code}\nhist(sbr$diff)\n```\n\n::: {.cell-output-display}\n![](data-sads_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\nUsing the simpleboot and boot packages:\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-6_897a6e9d64389318f174fffadfcb7402'}\n\n```{.r .cell-code}\nlibrary(simpleboot)\nb.mean <- one.boot(sbr$diff, mean, 999)\nboot::boot.ci(b.mean)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in boot::boot.ci(b.mean): bootstrap variances needed for studentized\nintervals\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 999 bootstrap replicates\n\nCALL : \nboot::boot.ci(boot.out = b.mean)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 0.1255,  0.1946 )   ( 0.1200,  0.1895 )  \n\nLevel     Percentile            BCa          \n95%   ( 0.1295,  0.1990 )   ( 0.1310,  0.2015 )  \nCalculations and Intervals on Original Scale\n```\n:::\n\n```{.r .cell-code}\nmean(b.mean$data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1595\n```\n:::\n\n```{.r .cell-code}\nhist(b.mean)\n```\n\n::: {.cell-output-display}\n![](data-sads_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nUsing the bootstrap package:\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-7_1d33ad2b9fa39e1b664fd8a6a27cfe44'}\n\n```{.r .cell-code}\nlibrary(bootstrap)\nb <- bootstrap(sbr$diff, 999, mean)\nquantile(b$thetastar, c(.025,.975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  2.5%  97.5% \n0.1285 0.1940 \n```\n:::\n\n```{.r .cell-code}\nmean(b$thetastar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1592718\n```\n:::\n\n```{.r .cell-code}\nsd(b$thetastar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01694609\n```\n:::\n\n```{.r .cell-code}\nse <- function(x) sqrt(var(x)/length(x))\nse(b$thetastar)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0005361504\n```\n:::\n:::\n\n\nBoth procedures shown above led to similar results. The 95% CIs of the differences did not include zero, so a significant improvement in accuracy can be inferred.\n\n### Parametric and non-parametric paired sample tests\n\nIn the case that two estimates are obtained by the same rater at different times, the data are not independent. For this situation, a **paired sample t-test** can be used for testing whether the mean difference between two sets of observations is zero. In this test, each subject (the leaf in our case) is measured or estimated twice, resulting in *pairs* of observations. If the assumptions of the test are violated (e.g. lack of normality), an equivalent non-parametric test can be used, such as the Wilcoxon, also known as **Wilcoxon signed-rank test**. It is used when your data are not normally distributed.\n\nLet's apply these two tests for our data and compare the results. We need to check whether the data are normally distributed. Then, we can also check whether the variances are equal.\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-8_f61920ddb1eca984fa4b6f25c580fd70'}\n\n```{.r .cell-code}\n# normality test\nshapiro.test(sbr$aided)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  sbr$aided\nW = 0.82529, p-value = 0.002111\n```\n:::\n\n```{.r .cell-code}\nshapiro.test(sbr$unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  sbr$unaided\nW = 0.83769, p-value = 0.003338\n```\n:::\n\n```{.r .cell-code}\n# equal variance test\nvar.test(sbr$aided, sbr$unaided)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tF test to compare two variances\n\ndata:  sbr$aided and sbr$unaided\nF = 0.037789, num df = 19, denom df = 19, p-value = 1.53e-09\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.01495720 0.09547109\nsample estimates:\nratio of variances \n        0.03778862 \n```\n:::\n\n```{.r .cell-code}\n# paired t-test\nt.test(sbr$aided, sbr$unaided, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  sbr$aided and sbr$unaided\nt = 8.812, df = 19, p-value = 3.873e-08\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n 0.1216158 0.1973842\nsample estimates:\nmean of the differences \n                 0.1595 \n```\n:::\n\n```{.r .cell-code}\n# Wilcoxon test\nwilcox.test(sbr$aided, sbr$unaided, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in wilcox.test.default(sbr$aided, sbr$unaided, paired = TRUE): cannot\ncompute exact p-value with ties\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  sbr$aided and sbr$unaided\nV = 210, p-value = 9.449e-05\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\nAs shown above, the two assumptions were violated, so we could rely more confidently on the non-parametric test.\n\n### Mixed effects modeling\n\nMixed models are a form of linear modeling used for hierarchical data when the response variable has a normal distribution and the predictor variables are a mix of fixed and random effects. These models are also good when data points might not be fully independent of each other, which is the case in our example [@brown2021].\n\nHere we treat raters as random effects. We expect them to be samples from a larger population about which we are trying to draw conclusions. We can sample more raters who would be different from the ones we have and we can infer something about the whole population from the sampled in our analyses. The random effects capture variation that exists but isn't relevant to the question, like variation between subjects for which we have repeated measures.\n\nLet's start reshaping our data to the long format and assign them to a new data frame.\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-9_99274d7106f0561dd3409cacfc69cda9'}\n\n```{.r .cell-code}\nsbr2 <- sbr |> \n  pivot_longer(2:3, names_to = \"condition\", values_to = \"estimate\")\n```\n:::\n\n\nNow we fit the mixed model using the `lmer` function of the *lme4* package. We will fit the model to the logit of the estimate because they should be bounded between zero and one. Preliminary analysis using non-transformed or log-transformed data resulted in lack of normality of residuals and heterocedasticity (not shown).\n\n\n::: {.cell hash='data-sads_cache/html/unnamed-chunk-10_af68268dd94bff0f3f13bd8f8270a3b3'}\n\n```{.r .cell-code}\nlibrary(lme4) \nlibrary(car) # for logit function\nmix <- lmer(logit(estimate) ~ condition + (1 | rater), data = sbr2)\n\n# Check model performance\nlibrary(performance)\ncheck_model(mix)\n```\n\n::: {.cell-output-display}\n![](data-sads_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncheck_normality(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: residuals appear as normally distributed (p = 0.381).\n```\n:::\n\n```{.r .cell-code}\ncheck_heteroscedasticity(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Error variance appears to be homoscedastic (p = 0.961).\n```\n:::\n\n```{.r .cell-code}\n# Check effect of condition\ncar::Anova(mix)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table (Type II Wald chisquare tests)\n\nResponse: logit(estimate)\n           Chisq Df Pr(>Chisq)    \ncondition 458.44  1  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# Estimate the means for each group\nlibrary(emmeans)\nem <- emmeans(mix, ~ condition, transform = \"response\")\nem\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n condition response      SE   df lower.CL upper.CL\n aided        0.968 0.00359 25.5    0.960    0.975\n unaided      0.817 0.01719 25.5    0.781    0.852\n\nDegrees-of-freedom method: inherited from kenward-roger when re-gridding \nConfidence level used: 0.95 \n```\n:::\n\n```{.r .cell-code}\n# Contrast the means\npairs(em)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n contrast        estimate     SE   df t.ratio p.value\n aided - unaided    0.151 0.0149 25.5  10.141  <.0001\n\nDegrees-of-freedom method: inherited from kenward-roger when re-gridding \n```\n:::\n\n```{.r .cell-code}\n# plot the means with 95% CIs\nplot(em) +\n  coord_flip()+\n  xlim(0.7,1)\n```\n\n::: {.cell-output-display}\n![](data-sads_files/figure-html/unnamed-chunk-10-2.png){width=672}\n:::\n:::\n\n\nAs shown above, we can reject the null hypothesis that the means are the same between the two groups.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}