# Spatial patterns

## Introduction

A spatial disease pattern can be defined as the arrangement of diseased entities relative to each other and to the architecture of the host crop [@chapter2017] . Such arrangement is the realization of the underlying dispersal of the pathogen, from one or several sources within and/or outside the area of interest, under the influence of physical, biological and environmental factors.

The study of spatial patterns is conducted at a specific time or multiple times during the epidemic. When assessed multiple times, both spatial and temporal processes can be characterized. Because epidemics change over time, it is expected that spatial patterns are not constant but change over time as well. Usually, plant pathologists are interested in determining spatial patterns at one or various spatial scales, depending on the objective of the study. The scale of interest may be a leaf or root, plant, field, municipality, state, country or even intercontinental area. The diseased units observed may vary from lesions on a single leaf to diseased fields in a large production region.

The patterns can be classified into two main types that occur naturally: **random** or **aggregated**. The random pattern originates because the chances for the units (leaf, plant, crop) to be infected are equal and low, and are largely independent from each other. In aggregated spatial patterns, such chances are unequal and there is dependency among the units, for example, a healthy unit close to a diseased unit is at higher risk than more distant units.

A range of techniques, most based on statistical tests, can be used to detect deviations from randomness in space and the choice of the methods depends on the scale of observation. Usually, more than one test is applied for the same or different scales of interest depending on how the data are collected. Three general categories of statistical tests can be determined based on the spatial scale and type of data collected: intensively mapped (plant to plant); quadrat or plot count/incidence data; or distance among the diseased units.

## Intensively mapped

### Binary data

In this situation the individual plants are mapped, meaning that their relative positions to one another are known. It is the case when a census is used to map presence/absence data. The status of each unit (usually a plant) is noted is a binay variable. The plant is either diseased (D or 1) or non-diseased or healthy (H or 0). Several statistical tests can be used to detect a deviation from randomness. The most commonly used tests are runs, doublets and join count.

#### Runs test

A run is defined as a succession of one or more diseased or healthy plants, which are followed and preceded by a plant of the other disease status or no plant at all. There would be few runs if there is an aggregation of diseased or healthy plants and a large number of runs for a random mixing of diseased and healthy plants.

Let's create a vector of binary (0 = non-diseased; 1 = diseased) data representing a crop row with 20 plants and assign it to `y`. For plotting purposes, we make a dataframe for more complete information.

```{r}
y1 <- c(1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,1,1)
x1 <- c(1:20) # position of each plant
z1 <- 1
row1 <- data.frame(x1, y1, z1) # create a dataframe
```

We can then visualize the series using ggplot and count the number of runs as 7, aided by the color used to identify a run.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
row1 %>% 
  ggplot(aes(x1, z1, label = x1, color = factor(y1)))+
  geom_point(shape =15, size =6)+
  theme_void()+
  scale_x_continuous(breaks = max(z1))+
  scale_color_manual(values = c("grey80", "grey20"))+
  geom_text(vjust = 0, nudge_y = 0.5)+
coord_fixed()+
  ylim(-0.5,2.5)+
  theme(legend.position = "right")+
  labs(color = "Status", title = "Sequence of diseased (1) or non-diseased (0) units (plants)", 
       subtitle = "The numbers represent the position of the unit")
```

We can write a code in R and create a function named `oruns.test` for the ordinary runs test.

```{r}
oruns.test <- function(x) {
# identify the sequence
S <- x 
# Compute the number or runs
U = max(cumsum(c(1, diff(S)!=0)))
# Compute the number of diseased plants
m = sum(S)
# Count the total number of plants
N = length(S)
# Calculate the number of expected runs
EU = 1 + (2 * m*(N - m)/N)
# Calculate the standard deviation in the sample
sU = sqrt(2 * m * (N - m) * (2 * m *(N-m)-N)/ (N^2 *(N-1)))
# Calculate the z-value
Z = (U - EU)/sU
# Obtain the p-value for the Z
pvalue <- (2*pnorm(abs(Z), lower.tail=FALSE))
# test if Z is lower than 1.64
result <- ifelse(Z < 1.64, 
c("clustering"), 
c("randomness"))
# Print the results
print(paste("There are",U,"runs. The number of expected runs is", round(EU,1), "P-value:",round(pvalue,6), ". Alternative hypothesis: non-randomness"))
}
```

We can now run the test for the example series above.

```{r}
oruns.test(row1$y1)
```

There are built-in functions in R packages that allow for running the ordinary runs test. Let's load the packages and runt the test. Note that the results of the `runs.test` is the same as the one produced by our custom function.

```{r}
library(randtests)
runs.test(row1$y1, threshold = 0.5)

library(DescTools)
r <- RunsTest(row1$y1)

```

#### Doublets

Doublet analysis is used to compare the observed number or adjacent diseased plants, a doublet (DD or 11), to the number expected if the disease were randomly distributed in the yard. If the observed number is greater than the expected number, contagion within the field is suspected.

Let's manually produce a code to execute the doublets test. To facilitate, we can create a function and name it `doublets.test`. The only argument needed is the vector of binary data.

```{r}
doublets.test <- function(x) {
# Identify the sequence
S <- x
# Compute the number of doublets Db
matrix <- cbind(S[-length(S)], S[-1])
pairs <- table(data.frame(matrix))
Db <- pairs[2,2]
# Count the number of diseased plants
N <- length(S) 
# Count the number of total plants
m = sum(S) 
# Expected number of doublets
EDb = m *((m -1)/N)
# Standard deviation 
SDb = sqrt ( EDb * (1 - (2 / N)))
# Calculate the Z-value 
ZDb = (Db - EDb)/ SDb 
# two-sided P-value calculation
pvalue <- (2*pnorm(abs(ZDb), lower.tail = FALSE))
# Result of the test
result <- ifelse(abs(ZDb) >= 1.64, 
c("aggregation or clustering"), 
c("randomness")) 
# Print the results
print(paste("There are",Db,"doublets. The number of expected doublets is",EDb,".","P-value:", round(pvalue,4), ". Alternative hypothesis: non-randomness"))
}
```

```{r}
# Run the function calling the vector
doublets.test(row1$y1)
```

#### Join count

In this analysis, two adjacent plants may be classified by the type of join that links them: D-D, H-H or H-D. The orientation(s) of interest (along rows, across rows, diagonally, or a a combination o these) should be specified. The number of joins of the specified type in the orientation(s) of interest is then counted. The question is whether the observed join-count is large (or small) relative to that expected for a random pattern.

In R, we can use the `join.count` function of the `spdep` package to perform a joint count test. First we need to create the series of binary data from top to bottom and left to right. The data are shown in Fig. 9.13 in page 260 of the book chapter on spatial analysis [@chapter2017]. In the example, there are 5 rows and 5 columns. This will be informed later to run the test.

```{r}
# Enter the data
S2 <- c(1,0,1,1,0,
       1,1,0,0,0,
       1,0,1,0,0,
       1,0,0,1,0,
       0,1,0,1,1)
```

Visualize the two-dimensional array:

```{r}
# Convert to raster 
mapS2 <- raster::raster(matrix(S2, 5 ,5))

# Convert to data frame
mapS3 <- raster::as.data.frame(mapS2,xy=TRUE)

# Map using ggplot
mapS3 %>% 
  ggplot(aes(x, y, label = layer, fill = factor(layer)))+
  geom_tile(color = "black", size =1)+
  theme_void()+
  geom_text(size = 10)+
  labs(fill = "Status")+
  scale_fill_manual(values = c("white", "grey80"))
```

Load the library

```{r message=FALSE, warning=FALSE}
library(spdep)
```

First, we need to generate a list of neighbors (nb) for a grid of cells. This is performed with the `cell2nb` function by informing the number of rows and columns. The argument "rook" means shared edge, but it could be the "queen", for shared edge or vertex. We can use the default.

```{r}
nb <- cell2nb(nrow = 5, 
              ncol = 5, 
              type="rook")
```

The `joincount.test` function runs the BB join count test for spatial autocorrelation. From the function description, the method uses a spatial weights matrix in weights list form for testing whether same-status joins occur more frequently than would be expected if the zones were labelled in a spatially random way. We need to inform the sequence as factor and the nb object we created previously.

```{r}
joincount.test(factor(S2), 
                nb2listw(nb))
```

The function returns a list with a class for each of the status (in this case 0 and 1) with several components. We should look at the **P-value**. The alternative hypothesis (greater) is that the same status joins occur more frequently than expected if they were labelled in a spatial random way. In this case, we do not reject the null hypothesis of randomness.

We can run the ordinary runs and doublets tests, which only considers the adjacent neighbor, for the same series and compare the results.

```{r}
oruns.test(S2)
doublets.test(S2)
```

Let's repeat the procedure using the second array of data shown in the book chapter, for which the result is different. In this case, there is evidence to reject the null hypothesis, indicating aggregation of plants.

```{r}
S3 <- c(1,1,1,0,0,
       1,1,1,0,0,
       1,1,1,0,0,
       1,1,1,0,0,
       0,0,0,0,0)

joincount.test(factor(S3), 
                nb2listw(nb))
oruns.test(S3)

```
We can apply these tests for a real example epidemic data provided by the [epiphy](https://chgigot.github.io/epiphy/) R package. Let's work with part of the intensively mapped data on the incidence of tomato spotted wilt virus (TSWV) disease in field trials reported by Cochran (1936) and Bald (1937). First, we need to load the library and then assign one dataframe (the dataset has two dataframes) of the dataset `tomato_tswv` to a new dataframe called `tswv_1929`.  

```{r message=FALSE, warning=FALSE}
library(epiphy)
tswv_1929 <- tomato_tswv$field_1929
head(tswv_1929) 
```

The inspection of the first rows of the dataframe shows five variables where x and y are spatial grid coordinates, t is assessment time, i is the status of the plant (0 = healthy, 1 = diseased) and n is the sampling unit size (here all one). Let's visualize these data for each sampling time.

```{r}
tswv_1929 %>% 
  ggplot(aes(x, y, fill = factor(i)))+
  geom_tile()+
  coord_fixed()+
  scale_fill_grey(start = 0.8, end = 0.2)+
  facet_wrap(~ t)+
  labs(fill = "Status")
```
Check the number of rows (y) and columns (x) for further preparing the neighbor object for the join count statistics. 

```{r}
tswv_1929 %>% 
  select(x, y) %>% 
  summary()
```
There are 60 rows and 24 columns.

```{r}
# Neighbor grid
nb <- cell2nb(nrow = 60, 
              ncol = 24, 
              type="rook")

# Pull the binary sequence of time 1
S1 <- tswv_1929 %>% 
  filter(t == "1") %>% 
  pull(i)

joincount.test(factor(S1), 
                nb2listw(nb))
```

We can repeat the procedure for time 2 and time 3.

```{r}
# Pull the binary sequence of time 1
S2 <- tswv_1929 %>% 
  filter(t == "2") %>% 
  pull(i)

joincount.test(factor(S2), 
                nb2listw(nb))

# Pull the binary sequence of time 1
S3 <- tswv_1929 %>% 
  filter(t == "3") %>% 
  pull(i)

joincount.test(factor(S3), 
                nb2listw(nb))

```








