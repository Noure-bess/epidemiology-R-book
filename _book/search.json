[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R4PDE",
    "section": "",
    "text": "R for Plant Disease Epidemiology (R4PDE) is a book project in the development stage. It is based on my teaching notes of a graduate course, currently FIP 602 - Plant Disease Epidemiology, offered every year for students of the Graduate Program in Plant Pathology of the Universidade Federal de Viçosa.\nThis book is intended for those who have a minimum knowledge of R programming using the RStudio IDE and the tidyverse ecosystem. I make use of several general and specific R packages for conducting the most common tasks related with the analysis of plant disease epidemiology data."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "Madden, L. V., Hughes, G., and Bosch, F. van den. 2017. The study of plant disease epidemics. Available at: http://dx.doi.org/10.1094/9780890545058."
  },
  {
    "objectID": "temporal.html",
    "href": "temporal.html",
    "title": "2  Temporal analysis",
    "section": "",
    "text": "A key understanding of the epidemics relates to the knowledge of rates and patterns. Epidemics can be viewed as dynamic systems that change their state as time goes. The first and simplest way to characterize such changes in time is to produce a graphical plot called disease progress curve (DPC). This curve can be obtained as long as the intensity of the disease (y) in the host population is assessed sequentially in time (t). A DPC summarizes the interaction of the three main components of the disease triangle occurring during the epidemic. The curves can vary greatly in shape according to variations in each of the components, in particular due to management practices that alter the course of the epidemics and for which the goal is to stop disease increase.\nThe depiction and analysis of disease progress curves can provide useful information for gaining understanding of the underlying epidemic process. In a practical manner, the curves are extensively used to evaluate how disease control measures affect epidemics. When characterizing progress curves, a researcher may be interested in describing and comparing epidemics that result from different treatments, or simply in their variations as affected by changes in environment, host or pathogen.\nMathematical models can be fitted to the disease progress curve data to express epidemic progress in terms of rates and absolute/relative quantities. The latter can be accomplished using population dynamics (or growth-curve) models for which the estimated parameters are usually meaningful biologically and appropriately describe epidemics that do not decrease in disease intensity. By fitting an appropriate model to the progress curve data, another set of parameters is available to the researcher when attempting to represent, understand or compare epidemics. \n\n\nThe family of models that describe the growth of epidemics, hence population dynamics model, are known as deterministic models of continuous time (Madden et al. 2017). These models are usually fitted to DPC data to obtain two or more biologically meaningful parameters.\nIn this tutorial, these models and their formulations are shown using R scripts to simulate the theoretical curves for each model. The reader should be capable of opening R or RStudio software and reproduce the analysis by copying and pasting the codes. Hence, a very basic knowledge of R is required.\n\n\n\n\n\n\nNote\n\n\n\nNote that I use pipes in my programming to express a sequence of multiple operations in a more intuitive way.\n\n\nLet’s start loading essential packages for programming, customizing the outputs and defining a global ggplot theme.\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(patchwork)\ntheme_set(theme_light())\nknitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)"
  },
  {
    "objectID": "temporal.html#non-flexible-models",
    "href": "temporal.html#non-flexible-models",
    "title": "2  Temporal analysis",
    "section": "2.2 Non-flexible models",
    "text": "2.2 Non-flexible models\nThese population dynamics models require at least two parameters, hence they are known as non-flexible, as opposed to the flexible ones for which there are at least one additional (third) parameter.\nFollowing the convention proposed by (Madden et al. 2017) in their book “The study of plant disease epidemics”:\n\ntime is represented by \\(t\\)\ndisease intensity by \\(y\\)\nthe rate of change in \\(y\\) between two time units is represented by \\(\\frac{dy}{dt}\\)\n\nNow we can proceed and learn which non-flexible models exist and for which situation they are more appropriate.\n\n2.2.1 Exponential\nThe differential equation for the exponential model is given by\n\\(\\frac{dy}{dt} = r_E.y\\),\nwhere \\(r_E\\) is the apparent infection rate (subscript E for this model) (sensu Vanderplank) and \\(y\\) is the disease intensity. Biologically, this formulation suggests that diseased plants, or \\(y\\), and \\(r_E\\) at each time contribute to disease increase. The value of \\(\\frac{dy}{dt}\\) is minimal when \\(y = 0\\) and increases exponentially with the increase in \\(y\\).\nThe integral for the exponential model is given by\n\\(y = y_0 e^{r_Et}\\),\nwhere \\(y0\\) is and \\(r\\) are obtained via estimation. Let’s simulate two curves by varying \\(r\\) while fixing \\(y0\\) and varying the latter while fixing \\(r_E\\). We produce the two plots in ggplot and add the predicted curve using the `stat_function`. But first, we need to define values for the two model parameters. Further modifications to these values will be handled directly in the simulation (e.g. doubling infection rate, reducing initial inoculum by half, etc.).\n\ny0 <- 0.001 \nr <- 0.06 \ntmax <- 60 # maximum duration t of the epidemics\ndat <- data.frame(t = seq(1:tmax), y = seq(0:1)) # define the axes\n\nIn the plot below, note that the infection rate in one curve was doubled (\\(r\\) = 0.12)\n\ndat %>%\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) y0 * exp(r * t), linetype = 1) +\n  stat_function(fun = function(t) y0 * exp(r * 2 * t), linetype = 2) +\n  ylim(0, 1) +\n  labs(\n    title = \"Exponential model\",\n    subtitle = \"2 times r (dashed) same y0\",\n    x = \"Time\"\n  )\n\n\n\n\nNow the inoculum was increased five times while using the same doubled rate.\n\ndat %>%\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) y0 * exp(r * 2 * t), linetype = 1) +\n  stat_function(fun = function(t) y0 * 5 * exp(r * 2 * t), linetype = 2) +\n  ylim(0, 1) +\n  labs(title = \"Exponential model\", x = \"Time\",\n       subtitle = \"5 times y0 (dashed) same r\")\n\n\n\n\n\n\n2.2.2 Monomolecular\nThe differential of the monomolecular model is given by\n\\(\\frac{dy}{dt} = r_M (1-y)\\)\nwhere now the \\(r_M\\) is the rate parameter of the monomolecular model and \\((1-y)\\) is the proportion of non-infected (healthy) individuals or host tissue. Note that \\(\\frac{dy}{dt}\\) is maximum when \\(y = 0\\) and decreases when \\(y\\) approaches 1. Its decline is due to decrease in the proportion of individuals or healthy sites with the increase in \\(y\\). Any inoculum capable of infecting the host will more likely land on infected individuals or sites.\nThe integral of the monomolecular model is given by\n\\(\\frac{dy}{dt} = 1 - (1-y)e^{-r_Mt}\\)\nThis model commonly describes the temporal patterns of the monocyclic epidemics. In those, the inoculum produced during the course of the epidemics do not contribute new infections. Therefore, different from the exponential model, disease intensity \\(y\\) does not affect the epidemics and so the absolute rate is proportional to \\((1-y)\\).\nLet’s simulate two monomolecular curve with different rate parameters where one is one third of the other.\n\ndat %>%\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-r * t))) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-(r / 3) * t))) +\n  labs(title = \"Monomolecular model\",\n         subtitle = \"Fixed y0 = 0.001\", x = \"Time\"\n       ) +\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"r = 0.06\") +\n  annotate(geom = \"text\", x = 50, y = 0.55, label = \"r = 0.02\")\n\n\n\n\nNow inoculum was increased 100 times with the reduced rate.\n\ndat %>%\n  ggplot(aes(t, y)) +\n  stat_function(fun = function(t) 1 - ((1 - y0) * exp(-r / 2 * t))) +\n  stat_function(fun = function(t) 1 - ((1 - (y0 * 100)) * exp(-r / 2 * t))) +\n  labs(title = \"Monomolecular model\", \n       subtitle = \"Fixed r = 0.06\", x = \"Time\") +\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"y0 = 0.01\") +\n  annotate(geom = \"text\", x = 45, y = 0.65, label = \"y0 = 0.001\")\n\n\n\n\n\n\n2.2.3 Logistic\nThe logistic model is a more elaborated version of the two previous models as it incorporates the features of them both. Its differential is given by\n\\(\\frac{dy}{dt} = r_L. y . (1 - y)\\),\nwhere \\(r_L\\) is the infection rate of the logistic model, \\(y\\) is the proportion of diseased individuals or host tissue and \\((1-y)\\) is the proportion of non-affected individuals or host area.\nBiologically, \\(y\\) in its differential equation implies that \\(\\frac{dy}{dt}\\) increases with the increase in \\(y\\) (as in the exponential) because more disease means more inoculum. However, \\((1-y)\\) leads to a decrease in \\(\\frac{dy}{dt}\\) when \\(y\\) approaches the maximum \\(y=1\\), because the proportion of healthy individuals or host area decreases (as in the monomolecular). Therefore, \\(\\frac{dy}{dt}\\) is minimal at the onset of the epidemics, reaches a maximum when \\(y/2\\) and declines until \\(y=1\\).\nThe integral is given by\n\\(y = \\frac{1}{1 + (1-y_0).e^{-r.t}}\\),\nwhere \\(r_L\\) is the apparent infection rate of the logistic model and \\(y0\\) is the disease intensity at \\(t=0\\). This model provides a good fit to polycyclic epidemics.\nLet’s check two curves where in one the infection rate is double while keeping the same initial inoculum.\n\ndat %>%\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 2 * t))\n  ) +\n  stat_function(fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 4 * t))) +\n  labs(title = \"Logistic model\", subtitle = \"Fixed y0 = 0.001\", x = \"Time\") +\n  annotate(geom = \"text\", x = 41, y = 0.77, label = \"r = 0.18\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"r = 0.024\")\n\n\n\n\nNow the inoculum is reduced 10 times for a same infection rate.\n\ndat %>%\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) 1 / (1 + ((1 - (y0 / 10)) / (y0 / 10)) * exp(-r * 3 * t))\n  ) +\n  stat_function(fun = function(t) 1 / (1 + ((1 - y0) / y0) * exp(-r * 3 * t))) +\n  labs(title = \"Logistic model\", subtitle = \"Fixed r = 0.24\", x = \"Time\") +\n  annotate(geom = \"text\", x = 35, y = 0.77, label = \"y0 = 0.001\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"y0 = 0.0001\")\n\n\n\n\n\n\n2.2.4 Gompertz\nThe Gompertz model is similar to the logistic and also provides a very good fit to several polycyclic diseases. The differential equation is given by\n\\(\\frac{dy}{dt} = r_G.[ln(1) - ln(y)]\\)\nDifferently from the logistic, the variable representing the non-infected individuals or host area is \\(-ln(y)\\). The integral equation is given by\n\\(y = e^{(ln(y0)).{e^{-r_G.t)}}}\\),\nwhere \\(r_G\\) is the apparent infection rate for the Gompertz models and \\(y_0\\) is the disease intensity at \\(t = 0\\).\nLet’s check curves for two rates.\n\ndat %>%\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) exp(log(y0) * exp(-r/2 * t))\n  ) +\n  stat_function(fun = function(t) exp(log(y0) * exp(-r*2 * t))) +\n  labs(title = \"Gompertz model\", subtitle = \"Fixed y0 = 0.001\", x = \"Time\") +\n  annotate(geom = \"text\", x = 41, y = 0.77, label = \"r = 0.12\") +\n  annotate(geom = \"text\", x = 50, y = 0.10, label = \"r = 0.03\")\n\n\n\n\nAnd those when inoculum was reduced thousand times.\n\ndat %>%\n  ggplot(aes(t, y)) +\n  stat_function(\n    linetype = 2,\n    fun = function(t) exp(log(y0) * exp(-r*2 * t))\n  ) +\n  stat_function(fun = function(t) exp(log(y0/1000) * exp(-r*2 * t))) +\n  labs(title = \"Gompertz model\", subtitle = \"Fixed r = 0.12\", x = \"Time\") +\n  annotate(geom = \"text\", x = 15, y = 0.77, label = \"y0 = 0.001\") +\n  annotate(geom = \"text\", x = 25, y = 0.10, label = \"y0 = 0.00001\")"
  },
  {
    "objectID": "temporal.html#model-fitting",
    "href": "temporal.html#model-fitting",
    "title": "2  Temporal analysis",
    "section": "2.3 Model fitting",
    "text": "2.3 Model fitting\nIn this tutorial you will learn how to fit models to multiple actual disease progress curves (DPCs) data obtained from the literature. I will demonstrate how to fit and select the models using a new R package called epifitter. A few user friendly functions will help us decide which model to choose to obtain the parameters of interest and further compare the epidemics.\nTo illustrate, I will use two datasets available from Chapter 3 from the book, Study of Plant Disease Epidemics (Madden et al. 2017). In the book, SAS codes are presented to perform a few analysis. We then provide an alternative code for performing similar analysis, although not perfectly reproducing the results from the book.\n\n2.3.1 Non-replicated\nHere we will compare three DPCs of the incidence of tobacco etch, a virus disease, in peppers. Evaluations of incidence were evaluated at a 7-day interval up to 49 days.The data are available in chapter 4 (page 93). Let’s input the data manually and create a data frame. First column is the assessment time and the other columns correspond to the treatments, called groups in the book, from 1 to 3.\n\n2.3.1.1 Initial setup\nLoad essential packages and set parameters recursively.\n\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(patchwork)\nlibrary(ggthemes)\ntheme_set(theme_few())\nknitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)\noptions(digits = 3)\n\n\n\n2.3.1.2 Entering data\n\npepper <- \n  tibble::tribble(\n   ~t,  ~`1`,  ~`2`,  ~`3`,\n   0,  0.08, 0.001, 0.001,\n   7,  0.13,  0.01, 0.001,\n  14,  0.78,  0.09,  0.01,\n  21,  0.92,  0.25,  0.05,\n  28,  0.99,   0.8,  0.18,\n  35, 0.995,  0.98,  0.34,\n  42, 0.999,  0.99,  0.48,\n  49, 0.999, 0.999,  0.74\n  ) \n\n\n\n2.3.1.3 Visualize the DPCs\nBefore proceeding with model selection and fitting, let’s visualize the three epidemics. The code below reproduces quite exactly the top plot of Fig. 4.15 ((Madden et al. 2017) page 94). The appraisal of the curves might give us a hint on which models are the best candidates.\nBecause the data was entered in the wide format (each DPCs in a different columns) we need to reshape it to the tidyverse-suitable format, which is the long format. The pivot_longer function will do the job of reshaping from wide to long format so we can finally use the ggplot function to produce the plot.\n\npepper %>% \n  pivot_longer(2:4, names_to =\"treat\", values_to = \"inc\") %>% \n  ggplot (aes(t, inc, \n              linetype = treat, \n              shape = treat, \n              group = treat))+\n  geom_point(size =2)+\n  geom_line()+\n  annotate(geom = \"text\", x = 15, y = 0.84, label = \"1\")+\n  annotate(geom = \"text\", x = 23, y = 0.6, label = \"2\")+\n  annotate(geom = \"text\", x = 32, y = 0.33, label = \"3\")+\n  labs(y = \"Disease incidence (y)\",\n       x = \"Time (days)\")+\n  theme(legend.position = \"none\")\n\n\n\n\nMost of the three curves show a sigmoid shape with the exception of group 3 that resembles an exponential growth, not reaching the maximum value, and thus suggesting an incomplete epidemic. We can easily eliminate the monomolecular and exponential models and decide on the other two non-flexible models: logistic or Gompertz. To do that, let’s proceed to model fitting and evaluate the statistics for supporting a final decision. There are two modeling approaches for model fitting in epifitter: the linear or nonlinear parameter-estimation methods.\n\n\n2.3.1.4 Fitting: single epidemics\nAmong the several options offered by epifitter we start with the simplest one, which is fit a model to a single epidemics using the linear regression approach. For such, the fit_lin() requires two arguments: time (time) and disease intensity (y) each one as a vector stored or not in a dataframe.\nSince we have three epidemics, fit_lin() will be use three times. The function produces a list object with six elements. Let’s first look at the Stats dataframe of each of the three lists named epi1 to epi3.\n\nlibrary(epifitter)\nepi1 <- fit_lin(time = pepper$t,  \n                y = pepper$`1` )\nepi1$Stats\n\n                CCC r_squared   RSE\nGompertz      0.985     0.970 0.591\nMonomolecular 0.984     0.968 0.543\nLogistic      0.978     0.957 0.824\nExponential   0.784     0.645 0.670\n\n\n\nepi2 <- fit_lin(time = pepper$t,  \n  y = pepper$`2` )\nepi2$Stats\n\n                CCC r_squared   RSE\nLogistic      0.996     0.992 0.452\nGompertz      0.971     0.943 0.841\nMonomolecular 0.925     0.860 1.068\nExponential   0.897     0.813 1.202\n\n\n\nepi3 <- fit_lin(time = pepper$t,  \n  y = pepper$`3` )\nepi3$Stats\n\n                CCC r_squared   RSE\nLogistic      0.983     0.967 0.605\nGompertz      0.983     0.966 0.226\nExponential   0.964     0.930 0.771\nMonomolecular 0.859     0.753 0.253\n\n\nThe statistics of the model fit confirms our initial guess that the predictions by the logistic or the Gompertz are closer to the observations than predictions by the other models. There is no much difference between them based on these statistics. However, to pick one of the models, it is important to inspect the curves with the observed and predicted values to check which model is best for all curves.\n\n\n2.3.1.5 Fitting: multiple epidemics\nBefore looking at the prediction, let’s use another handy function that allows us to simultaneously fit the models to multiple DPC data. Different from fit_lin(), fit_multi() requires the data to be structured in the long format where there is a column specifying each of the epidemics.\nLet’s then create a new data set called pepper2 using the data transposing functions of the tidyr package.\n\npepper2 <- pepper %>% \n  pivot_longer(2:4, names_to =\"treat\", values_to = \"inc\")\n\nNow we fit the models to all DPCs. Note that the name of the variable indicating the DPC code needs to be informed in strata_cols argument.\n\nepi_all <- fit_multi(\n  time_col = \"t\",\n  intensity_col = \"inc\",\n  data = pepper2,\n  strata_cols = \"treat\",\n  nlin = FALSE\n)\n\nNow let’s select the statistics of model fitting. Again, Epifitter ranks the models based on the CCC (the higher the better) but it is important to check the RSE as well - the lower the better. In fact, the RSE is more important when the goal is prediction.\n\nepi_all$Parameters %>% \n  select(treat, model, best_model, RSE, CCC)\n\n   treat         model best_model   RSE   CCC\n1      1      Gompertz          1 0.591 0.985\n2      1 Monomolecular          2 0.543 0.984\n3      1      Logistic          3 0.824 0.978\n4      1   Exponential          4 0.671 0.784\n5      2      Logistic          1 0.452 0.996\n6      2      Gompertz          2 0.841 0.971\n7      2 Monomolecular          3 1.068 0.925\n8      2   Exponential          4 1.202 0.897\n9      3      Logistic          1 0.605 0.983\n10     3      Gompertz          2 0.226 0.982\n11     3   Exponential          3 0.771 0.964\n12     3 Monomolecular          4 0.253 0.859\n\n\nTo be more certain about our decision, let’s advance to the final step which is to produce the plots with the observed and predicted values for each assessment time by calling the Data dataframe of the `epi_all list.\n\nepi_all$Data %>%\n filter(model %in% c(\"Gompertz\", \"Logistic\")) %>% \n  ggplot(aes(time, predicted, shape = treat)) +\n  geom_point(aes(time, y)) +\n  geom_line() +\n  facet_wrap(~ model) +\n coord_cartesian(ylim = c(0, 1)) + # set the max to 0.6\n  labs(\n    y = \"Disease incidence\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nOverall, the logistic model seems a better fit for all the curves. Let’s produce a plot with the prediction error versus time.\n\nepi_all$Data %>%\n filter(model %in% c(\"Gompertz\", \"Logistic\")) %>% \n  ggplot(aes(time, predicted -y, shape = treat)) +\n  geom_point() +\n  geom_line() +\n  geom_hline(yintercept = 0, linetype =2)+\n  facet_wrap(~ model) +\n coord_cartesian(ylim = c(-0.4, 0.4)) + # set the max to 0.6\n  labs(\n    y = \"Prediction error\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nThe plots above confirms the logistic model as good fit overall because the errors for all epidemics combined are more scattered around the non-error line.\n\n  epi_all$Parameters %>%\n    filter(model == \"Logistic\") %>%\n    select(treat, y0, y0_ci_lwr, y0_ci_upr, r, r_ci_lwr, r_ci_upr \n)\n\n  treat       y0 y0_ci_lwr y0_ci_upr     r r_ci_lwr r_ci_upr\n1     1 0.093504  0.027321   0.27473 0.210    0.166    0.255\n2     2 0.001373  0.000672   0.00280 0.278    0.254    0.303\n3     3 0.000813  0.000313   0.00211 0.175    0.143    0.208\n\n\nWe can produce a plot for visual inference on the differences in the parameters.\n\np1 <- epi_all$Parameters %>%\n  filter(model == \"Logistic\") %>%\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Time\",\n    y = \"r\"\n  )\n\np2 <- epi_all$Parameters %>%\n  filter(model == \"Logistic\") %>%\n  ggplot(aes(treat, 1 - exp(-y0))) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Time\",\n    y = \"y0\"\n  )\n\np1 | p2\n\n\n\n\n\n\n\n2.3.2 Designed experiments\nIn this next section, we will work with disease data collected over time in the same plot unit (also called repeated measures) from a designed experiment for evaluating and comparing treatment effects.\nAgain, we will use a dataset of progress curves shown in page 98 (Madden et al. 2017). The curves represent the incidence of soybean plants symptomatic for bud blight caused by tobacco streak virus. Four treatments (different planting dates) were evaluated in randomized complete block design with four replicates. There are four assessment in time for each curve. The data was stored as a csv file and will be loaded using read_csv() function and stored as dataframe called budblight.\n\n2.3.2.1 Loading data\n\nbudblight <- read_csv(\"data/bud-blight-soybean.csv\")\n\nLet’s have a look at the first six rows of the dataset and check the data type for each column. There is an additional column representing the replicates, called block.\n\nhead(budblight)\n\n# A tibble: 6 × 4\n  treat  time block     y\n  <chr> <dbl> <dbl> <dbl>\n1 PD1      30     1  0.1 \n2 PD1      30     2  0.3 \n3 PD1      30     3  0.1 \n4 PD1      30     4  0.1 \n5 PD1      40     1  0.3 \n6 PD1      40     2  0.38\n\n\n\n\n2.3.2.2 Visualizing the DPCs\nLet’s have a look at the curves and produce a combo plot figure similar to Fig. 4.17 of the book, but without the line of the predicted values.\n\np3 <- budblight %>%\n  ggplot(aes(\n    time, y,\n    group = block,\n    shape = factor(block)\n  )) +\n  geom_point(size = 1.5) +\n  ylim(0, 0.6) +\n  theme(legend.position = \"none\")+\n  facet_wrap(~treat, ncol =1)+\n  labs(y = \"Disease incidence\",\n       x = \"Time (days after emergence)\")\n\n\np4 <- budblight %>%\n  ggplot(aes(\n    time, log(1 / (1 - y)),\n    group = block,\n    shape = factor(block)\n  )) +\n  geom_point(size = 2) +\n  facet_wrap(~treat, ncol = 1) +\n  theme(legend.position = \"none\")+\n  labs(y = \"Transformed incidence\", x = \"Time (days after emergence)\")\n\np3 | p4\n\n\n\n\n\n\n2.3.2.3 Model fitting\nRemember that the first step in model selection is the visual appraisal of the curve data linearized with the model transformation. In the case the curves represent complete epidemics (close to 100%) appraisal of the absolute rate (difference in y between two times) over time is also helpful.\nFor the treatments above, it looks like the curves are typical of a monocyclic disease (the case of soybean bud blight), for which the monomolecular is usually a good fit, but other models are also possible as well. For this exercise, we will use both the linear and the nonlinear estimation method.\n\n2.3.2.3.1 Linear regression\nFor convenience, we use the fit_multi() to handle multiple epidemics. The function returns a list object where a series of statistics are provided to aid in model selection and parameter estimation. We need to provide the names of columns (arguments): assessment time (time_col), disease incidence (intensity_col), and treatment (strata_cols).\n\nlin1 <- fit_multi(\n  time_col = \"time\",\n  intensity_col = \"y\",\n  data = budblight,\n  strata_cols = \"treat\",\n  nlin = FALSE\n)\n\nLet’s look at how well the four models fitted the data. Epifitter suggests the best fitted model (1 to 4, where 1 is best) for each treatment. Let’s have a look at the statistics of model fitting.\n\n  lin1$Parameters %>% \n    select(treat, best_model, model, CCC, RSE)\n\n   treat best_model         model   CCC    RSE\n1    PD1          1 Monomolecular 0.935 0.0981\n2    PD1          2      Gompertz 0.904 0.2223\n3    PD1          3      Logistic 0.871 0.4475\n4    PD1          4   Exponential 0.828 0.3612\n5    PD2          1 Monomolecular 0.955 0.0700\n6    PD2          2      Gompertz 0.931 0.1794\n7    PD2          3      Logistic 0.906 0.3877\n8    PD2          4   Exponential 0.880 0.3268\n9    PD3          1 Monomolecular 0.939 0.0683\n10   PD3          2      Gompertz 0.929 0.1716\n11   PD3          3      Logistic 0.909 0.3905\n12   PD3          4   Exponential 0.890 0.3388\n13   PD4          1      Gompertz 0.923 0.1747\n14   PD4          2 Monomolecular 0.895 0.0649\n15   PD4          3      Logistic 0.891 0.5241\n16   PD4          4   Exponential 0.874 0.4977\n\n\nAnd now we extract values for each parameter estimated from the fit of the monomolecular model.\n\n  lin1$Parameters %>%\n  filter(model == \"Monomolecular\") %>%\n  select(treat, y0, r)\n\n  treat     y0      r\n1   PD1 -0.573 0.0220\n2   PD2 -0.522 0.0190\n3   PD3 -0.449 0.0159\n4   PD4 -0.362 0.0112\n\n\nNow we visualize the fit of the monomolecular model (using filter function - see below) to the data together with the observed data and then reproduce the right plots in Fig. 4.17 from the book.\n\nlin1$Data %>%\n  filter(model == \"Monomolecular\") %>%\n  ggplot(aes(time, predicted)) +\n  geom_point(aes(time, y)) +\n  geom_line(size = 0.5) +\n  facet_wrap(~treat) +\n  coord_cartesian(ylim = c(0, 0.6)) + # set the max to 0.6\n  labs(\n    y = \"Disease incidence\",\n    x = \"Time (days after emergence)\"\n  )\n\n\n\n\nNow we can plot the means and respective 95% confidence interval of the apparent infection rate (\\(r\\)) and initial inoculum (\\(y_0\\)) for visual inference.\n\np5 <- lin1$Parameters %>%\n  filter(model == \"Monomolecular\") %>%\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Time\",\n    y = \"r\"\n  )\n\np6 <- lin1$Parameters %>%\n  filter(model == \"Monomolecular\") %>%\n  ggplot(aes(treat, 1 - exp(-y0))) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Time\",\n    y = \"y0\"\n  )\n\np5 | p2\n\n\n\n\n\n\n2.3.2.3.2 Non-linear regression\nTo estimate the parameters using the non-linear approach, we repeat the same arguments in the fit_multi function, but include an additional argument nlin set to TRUE.\n\nnlin1 <- fit_multi(\n  time_col = \"time\",\n  intensity_col = \"y\",\n  data = budblight,\n  strata_cols = \"treat\",\n  nlin = TRUE\n)\n\nLet’s check statistics of model fit.\n\nnlin1$Parameters %>%\n  select(treat, model, CCC, RSE, best_model)\n\n   treat         model   CCC    RSE best_model\n1    PD1 Monomolecular 0.938 0.0613          1\n2    PD1      Gompertz 0.917 0.0699          2\n3    PD1      Logistic 0.896 0.0770          3\n4    PD1   Exponential 0.854 0.0880          4\n5    PD2 Monomolecular 0.967 0.0421          1\n6    PD2      Gompertz 0.935 0.0573          2\n7    PD2      Logistic 0.908 0.0666          3\n8    PD2   Exponential 0.870 0.0767          4\n9    PD3 Monomolecular 0.957 0.0427          1\n10   PD3      Gompertz 0.926 0.0544          2\n11   PD3      Logistic 0.900 0.0620          3\n12   PD3   Exponential 0.870 0.0689          4\n13   PD4 Monomolecular 0.918 0.0460          1\n14   PD4      Gompertz 0.909 0.0479          2\n15   PD4      Logistic 0.894 0.0508          3\n16   PD4   Exponential 0.884 0.0527          4\n\n\nAnd now we obtain the two parameters of interest. Note that the values are not the sames as those estimated using linear regression, but they are similar and highly correlated.\n\n  nlin1$Parameters %>%\n    filter(model == \"Monomolecular\") %>%\n    select(treat, y0, r)\n\n  treat     y0      r\n1   PD1 -0.707 0.0238\n2   PD2 -0.634 0.0206\n3   PD3 -0.505 0.0167\n4   PD4 -0.350 0.0109\n\n\n\np7 <- nlin1$Parameters %>%\n  filter(model == \"Monomolecular\") %>%\n  ggplot(aes(treat, r)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = r_ci_lwr, ymax = r_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Time\",\n    y = \"r\"\n  )\n\np8 <- nlin1$Parameters %>%\n  filter(model == \"Monomolecular\") %>%\n  ggplot(aes(treat, y0)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin = y0_ci_lwr, ymax = y0_ci_upr),\n    width = 0,\n    size = 1\n  ) +\n  labs(\n    x = \"Time\",\n    y = \"y0\"\n  )\n\np7 | p8\n\n\n\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F., eds. 2017. CHAPTER 4: Temporal analysis i: Quantifying and comparing epidemics. In The American Phytopathological Society, p. 63–116. Available at: http://dx.doi.org/10.1094/9780890545058.004."
  },
  {
    "objectID": "spatial-gradients.html",
    "href": "spatial-gradients.html",
    "title": "3  Spatial gradients",
    "section": "",
    "text": "When modeling disease gradients, the distance is represented by \\(x\\), a continuous variable which can be expressed by various units (cm, m, km, etc). The gradient models, similar to the population dynamics models (disease progress) are of the deterministic type. The difference is that, for disease progress curves, disease intensity tends to increase with increasing time, while in disease gradients the disease intensity tends to decrease with increasing distance from the source of inoculum. Two models are most commonly fitted to data on disease gradients. More details about these models can be obtained it this tutorial.\n\n\nThe exponential model is also known as Kiyosawa & Shiyomi model. The differential of the exponential model is given by\n\\(\\frac{dy}{dx}\\) = \\(-b_{E}.y\\) ,\nwhere \\(b_{E}\\) is the exponential form of the rate of decline and \\(y\\) is the disease intensity. This model suggests that \\(y\\) (any disease intensity) is greater close to the source of inoculum, or at the distance zero. The integral form of the model is given by\n\\(y = a . e^{-b.x}\\) ,\nwhere \\(a\\) is the disease intensity at the distance zero and \\(b\\) is the rate of decline, in this case negative because disease intensity decreases with the increase of the distance from inoculum source. Let’s make a plot for two disease gradients of varying parameters for this model.\nFirst we need to load essential packages for programming, customizing the outputs and defining a global ggplot theme.\n\nlibrary(tidyverse)\nlibrary(ggthemes)\nlibrary(patchwork)\ntheme_set(theme_light())\nknitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)\n\nSet the parameters for the exponential model with two rates and same inoculum at the source:\n\na1 <- 0.2 # y at distance zero for gradient 1\na2 <- 0.2 # y at distance zero for gradient 2\nb1 <- 0.1 # decline rate for gradient 1\nb2 <- 0.05 # decline rate for gradient 2\nmax1 <- 80 # maximum distance for gradient 1\nmax2 <- 80 # maximum distance for gradient 2\ndat <- data.frame(x = seq(1:max1), y = seq(0:a1))\n\nThe following code allows to visualize the model predictions.\n\ndat %>%\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) a1 * exp(-b1 * x), linetype = 1) +\n  stat_function(fun = function(x) a2 * exp(-b2 * x), linetype = 2) +\n  ylim(0, a1) +\n  annotate(\"text\", x = 20, y = 0.04, label = \"b = 0.1\") +\n  annotate(\"text\", x = 20, y = 0.10, label = \"b = 0.05\") +\n  labs(\n    title = \"Exponential model\",\n    subtitle = \"\",\n    x = \"Distance (m)\",\n    y = \"Disease incidence (proportion)\"\n  )\n\n\n\n\n\n\n\nAlso known as the modified Gregory’s model (Gregory was a pioneer in the use this model to describe plant disease gradients). In the power law model, \\(Y\\) is proportional to the power of the distance, and is given by:\n\\(Y = a_{P}.x - b_{P}\\)\nwhere \\(a_{P}\\) and \\(b_{P}\\) are the two parameters of the power law model. They differ from the exponential because as closer to \\(x\\) is to zero, \\(Y\\) is indefinitely large (not meaningful biologically). However, the model can still be useful because it produces realistic values at any distance \\(x\\) away from the source. The values of the \\(a_{P}\\) parameter should be interpreted in accord to the scale of \\(x\\), whether in centimeters or meters. If the distance between the source and the first measure away from the source is 0.5m, it is so more appropriate to record the distance in cm than in m or km.\nOnce \\(y\\) at the distance zero from the source is undefined when using the power law model, this is usually modified by the addition of a positive constant \\(C\\) in \\(x\\):\n\\(Y = a_{P}.(x + C) - b_{P}\\)\nFor this reason, the model is named as the modified power law. Here, the constant \\(C\\) is of the same unit of \\(x\\). At the distance zero, the positive constant is a term that express the size of the inoculum source. In other words, the \\(a\\) parameter is a theoretical value of \\(Y\\) at the distance \\(1-C\\) from the center of the inoculum source.\nLet’s plot two gradients with two rate parameters for the modified power law model:\n\nC <- 0.5\na1 <- 0.2 # y at zero distance for gradient 1\na2 <- 0.2 # y at zero distance for gradient 2\nb1 <- 0.5 # decline rate for gradient 1\nb2 <- 0.7 # decline rate for gradient 2\nmax1 <- 80 # maximum distance for gradient 1\nmax2 <- 80 # maximum distance for gradient 2\ndat2 <- data.frame(x = seq(1:max1), y = seq(0:a1))\n\n\ndat2 %>%\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) a1 * ((x + C)^-b1), linetype = 1) +\n  stat_function(fun = function(x) a2 * ((x + C)^-b2), linetype = 2) +\n  ylim(0, a1 - 0.02) +\n  annotate(\"text\", x = 20, y = 0.03, label = \"b = 0.1\") +\n  annotate(\"text\", x = 20, y = 0.06, label = \"b = 0.05\") +\n  labs(\n    title = \"Modified Power Law\",\n    subtitle = \"\",\n    x = \"Distance (m)\",\n    y = \"Disease incidence\"\n  )\n\n\n\n\nThe differential equation of the power law model is given by:\n\\(\\frac{dy}{dx}\\) = \\(\\frac{-b_{P}.Y}{x - C}\\)\nSimilar to the exponential model, \\(\\frac{dy}{dx}\\) is proportional to \\(Y\\), meaning that the gradient is steeper (more negative) at the highest disease intensity value, usually closer to the source."
  },
  {
    "objectID": "spatial-gradients.html#linearization-of-the-models",
    "href": "spatial-gradients.html#linearization-of-the-models",
    "title": "3  Spatial gradients",
    "section": "3.2 Linearization of the models",
    "text": "3.2 Linearization of the models\n\n3.2.1 Transformations of y\nThe gradient models, again similar to the temporal disease models, are non linear in their parameters. The model is intrinsically linear if transformations are applied (according to the model) in both sides of the equations. The linear model in its generic state is given by\n\\(y* = a* + bx\\) ,\nwhere the asterisk in \\(a\\) indicated that one of the transformations was applied in \\(y\\) that produced the linear model. Note that \\(a*\\) is the transformed version of the initial disease intensity, which needs to be returned to the original scale according to the respective back-transformation. Follows the linearized form of the two most common gradient models.\n\\(ln(y) = ln(a_{E}) - b_{E}. x\\)\n\\(ln(y) = ln(a_{P}) - b_{E}. ln(x+C)\\)\n\n\n3.2.2 Plot for the linearized form of models\nLet’s visualize the linearization of the exponential model with two different slopes (gradient 1 and 2). Note that the transformation used was \\(ln(y)\\).\nFollows the linearization of the modified power law model.\n\nC <- 0.5\na1 <- 0.2 # y at zero distance for gradient 1\na2 <- 0.2 # y at zero distance for gradient 2\nb1 <- 0.5 # decline rate for gradient 1\nb2 <- 0.7 # decline rate for gradient 2\nmax1 <- 80 # maximum distance for gradient 1\nmax2 <- 80 # maximum distance for gradient 2\ndat2 <- data.frame(x = seq(1:max1), y = seq(0:a1))\n\ndat2 %>%\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) log(a1) - (b1 * x), linetype = 1) +\n  stat_function(fun = function(x) log(a2) - (b2 * x), linetype = 2) +\n  labs(\n    title = \"Exponential\",\n    subtitle = \"\",\n    x = \"log of distance (m)\",\n    y = \"log of disease incidence\"\n  )\n\n\n\n\nFollows the linearization of the modified power law model. Note that the transformation used was \\(ln(y)\\) and \\(ln(x+C)\\) .\n\nC <- 0.5\na1 <- 0.2 # y at zero distance for gradient 1\na2 <- 0.2 # y at zero distance for gradient 2\nb1 <- 0.5 # decline rate for gradient 1\nb2 <- 0.7 # decline rate for gradient 2\nmax1 <- log(80) # maximum distance for gradient 1\nmax2 <- log(80) # maximum distance for gradient 2\ndat2 <- data.frame(x = seq(1:max1), y = seq(0:a1))\n\ndat2 %>%\n  ggplot(aes(x, y)) +\n  stat_function(fun = function(x) log(a1) - (b1 * log(x + C)), linetype = 1) +\n  stat_function(fun = function(x) log(a2) - (b2 * log(x + C)), linetype = 2) +\n  labs(\n    title = \"Modified Power Law\",\n    subtitle = \"\",\n    x = \"log of distance (m)\",\n    y = \"log of disease incidence\"\n  )"
  },
  {
    "objectID": "spatial-gradients.html#model-fitting",
    "href": "spatial-gradients.html#model-fitting",
    "title": "3  Spatial gradients",
    "section": "3.3 Model fitting",
    "text": "3.3 Model fitting\n\n3.3.1 Dataset\nThe hypothetical data below shows a gradient for the number of lesions counted at varying distances in meters from the source. Let’s create two vectors, one for the distances \\(x\\) and the other for the lesion count \\(Y\\), and then a dataframe by combining the two vectors.\n\n# create the two vectors\nx <- c(0.8, 1.6, 2.4, 3.2, 4, 7.2, 12, 15.2, 21.6, 28.8)\nY <- c(184.9, 113.3, 113.3, 64.1, 25, 8, 4.3, 2.5, 1, 0.8)\ngrad1 <- data.frame(x, Y) # create the dataframe\ngrad1 # show the gradient\n\n      x     Y\n1   0.8 184.9\n2   1.6 113.3\n3   2.4 113.3\n4   3.2  64.1\n5   4.0  25.0\n6   7.2   8.0\n7  12.0   4.3\n8  15.2   2.5\n9  21.6   1.0\n10 28.8   0.8\n\n\n\n\n3.3.2 Visualize the gradient\n\ngrad1 %>% \n  ggplot(aes(x, Y))+\n  geom_point()+\n  geom_line()+\n  labs(y = \"Lesion count\",\n       x = \"Distance (m)\")\n\n\n\n\n\n\n3.3.3 Linear regression\nA linear regression model is fitted to the transformed variables according to the model. The higher the coefficient of determination, the better is the fit of the model to the data.\nExponential model\n\nreg_exp <- lm(log(Y) ~ x, data = grad1)\nsummary(reg_exp)\n\n\nCall:\nlm(formula = log(Y) ~ x, data = grad1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.04868 -0.58973 -0.00144  0.59572  0.99554 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  4.57705    0.35222  12.995 1.17e-06 ***\nx           -0.20124    0.02656  -7.576 6.45e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7612 on 8 degrees of freedom\nMultiple R-squared:  0.8777,    Adjusted R-squared:  0.8624 \nF-statistic: 57.39 on 1 and 8 DF,  p-value: 6.45e-05\n\n\nPower law model with \\(C = 0\\).\n\nreg_p <- lm(log(Y) ~ log(x), data = grad1)\nsummary(reg_p)\n\n\nCall:\nlm(formula = log(Y) ~ log(x), data = grad1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.72281 -0.11989 -0.03146  0.08755  0.65267 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   5.5638     0.2456   22.66 1.53e-08 ***\nlog(x)       -1.6978     0.1191  -14.26 5.71e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4235 on 8 degrees of freedom\nMultiple R-squared:  0.9621,    Adjusted R-squared:  0.9574 \nF-statistic: 203.3 on 1 and 8 DF,  p-value: 5.71e-07\n\n\nPower law model with \\(C = 0.4\\).\n\nreg_pm <- lm(log(Y) ~ log(x + 0.4), data = grad1)\nsummary(reg_pm)\n\n\nCall:\nlm(formula = log(Y) ~ log(x + 0.4), data = grad1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.53733 -0.17258 -0.03646  0.08450  0.56928 \n\nCoefficients:\n             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    6.1007     0.2283   26.73 4.13e-09 ***\nlog(x + 0.4)  -1.8841     0.1084  -17.38 1.22e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3495 on 8 degrees of freedom\nMultiple R-squared:  0.9742,    Adjusted R-squared:  0.971 \nF-statistic: 302.2 on 1 and 8 DF,  p-value: 1.223e-07\n\n\nGraphs for the fitted models\nExponential\n\ngrad1 %>% \n  ggplot(aes(x, log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_exp)[[2]], intercept = coef(reg_exp)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Distance (m)\")\n\n\n\n\nPower law model\n\ngrad1 %>% \n  ggplot(aes(log(x), log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_p)[[2]], intercept = coef(reg_p)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Log of distance\")\n\n\n\n\nModified power law model\n\ngrad1 %>% \n  ggplot(aes(log(x+0.4), log(Y)))+\n  geom_point()+\n  geom_line()+\n  geom_abline(slope = coef(reg_pm)[[2]], intercept = coef(reg_pm)[[1]])+\n labs(y = \"Log of Lesion count\",\n       x = \"Log of distance (m)\")\n\n\n\n\nConclusion: The modified power law model provided the best fit."
  },
  {
    "objectID": "spatial-patterns.html",
    "href": "spatial-patterns.html",
    "title": "4  Spatial patterns",
    "section": "",
    "text": "A spatial disease pattern can be defined as the arrangement of diseased entities relative to each other and to the architecture of the host crop (Madden et al. 2017) . Such arrangement is the realization of the underlying dispersal of the pathogen, from one or several sources within and/or outside the area of interest, under the influence of physical, biological and environmental factors.\nThe study of spatial patterns is conducted at a specific time or multiple times during the epidemic. When assessed multiple times, both spatial and temporal processes can be characterized. Because epidemics change over time, it is expected that spatial patterns are not constant but change over time as well. Usually, plant pathologists are interested in determining spatial patterns at one or various spatial scales, depending on the objective of the study. The scale of interest may be a leaf or root, plant, field, municipality, state, country or even intercontinental area. The diseased units observed may vary from lesions on a single leaf to diseased fields in a large production region.\nThe patterns can be classified into two main types that occur naturally: random or aggregated. The random pattern originates because the chances for the units (leaf, plant, crop) to be infected are equal and low, and are largely independent from each other. In aggregated spatial patterns, such chances are unequal and there is dependency among the units, for example, a healthy unit close to a diseased unit is at higher risk than more distant units.\nA range of techniques, most based on statistical tests, can be used to detect deviations from randomness in space and the choice of the methods depends on the scale of observation. Usually, more than one test is applied for the same or different scales of interest depending on how the data are collected. Three general categories of statistical tests can be determined based on the spatial scale and type of data collected: position of diseased units within a row or series of rows (plant to plant); quadrat or plot count data; or distance among the diseased units."
  },
  {
    "objectID": "spatial-patterns.html#position-and-status-within-a-row-plant-to-plant",
    "href": "spatial-patterns.html#position-and-status-within-a-row-plant-to-plant",
    "title": "4  Spatial patterns",
    "section": "4.2 Position and status within a row (plant to plant)",
    "text": "4.2 Position and status within a row (plant to plant)\nHere, the status of each unit (usually a plant) is noted as a nominal variable. The plant is either diseased (D or 1) or non-diseased or healthy (H or 0). These data are usually collected within a crop row, giving rise to a series of binary data. Several statistical tests can be used to detect a deviation from randomness. The most commonly used tests are runs, doublets and joint count statistics.\n\n4.2.1 Runs test\nThe runs test. Description.\nLet’s create a vector of binary (0 = non-diseased; 1 = diseased) data representing a crop row with 20 plants and assign it to y. For plotting purposes, we make a dataframe for more complete information.\n\ny1 <- c(1,1,1,0,0,0,0,0,1,0,0,0,0,1,1,0,0,0,1,1)\nx1 <- c(1:20) # position of each plant\nz1 <- 1\nrow1 <- data.frame(x1, y1, z1) # create a dataframe\n\nWe can then visualize the series using ggplot.\n\nlibrary(tidyverse)\nrow1 %>% \n  ggplot(aes(x1, z1, label = x1, color = factor(y1)))+\n  geom_point(shape =15, size =6)+\n  theme_void()+\n  scale_x_continuous(breaks = max(z1))+\n  scale_color_manual(values = c(\"green\", \"red\"))+\n  geom_text(vjust = 0, nudge_y = 0.5)+\ncoord_fixed()+\n  ylim(-0.5,2.5)+\n  theme(legend.position = \"right\")+\n  labs(color = \"Status\", title = \"Sequence of diseased (1) or non-diseased (0) units (plants)\", \n       subtitle = \"The numbers represent the position of the unit\")\n\n\n\n\nWe can write a code in R and create a function named oruns.test for the ordinary runs test.\n\noruns.test <- function(x) {\n# identify the sequence\nS <- x \n# Compute the number or runs\nU = max(cumsum(c(1, diff(S)!=0)))\n# Compute the number of diseased plants\nm = sum(S)\n# Count the total number of plants\nN = length(S)\n# Calculate the number of expected runs\nEU = 1 + (2 * m*(N - m)/N)\n# Calculate the standard deviation in the sample\nsU = sqrt(2 * m * (N - m) * (2 * m *(N-m)-N)/ (N^2 *(N-1)))\n# Calculate the z-value\nZ = (U - EU)/sU\n# Obtain the p-value for the Z\npvalue <- (2*pnorm(abs(Z), lower.tail=FALSE))\n# test if Z is lower than 1.64\nresult <- ifelse(Z < 1.64, \nc(\"clustering\"), \nc(\"randomness\"))\n# Print the results\nprint(paste(\"There are\",U,\"runs. The number of expected runs is\", round(EU,1), \"P-value:\",round(pvalue,6), \". Alternative hypothesis: non-randomness\"))\n}\n\nWe can now run the test for the example series above.\n\noruns.test(row1$y1)\n\n[1] \"There are 7 runs. The number of expected runs is 10.6 P-value: 0.084166 . Alternative hypothesis: non-randomness\"\n\n\nThere are built-in functions in R packages that allow for running the ordinary runs test. Let’s load the packages and runt the test. Note that the results of the runs.test is the same as the one produced by our custom function.\n\nlibrary(randtests)\nruns.test(row1$y1, threshold = 0.5)\n\n\n    Runs Test\n\ndata:  row1$y1\nstatistic = -1.727, runs = 7, n1 = 8, n2 = 12, n = 20, p-value =\n0.08417\nalternative hypothesis: nonrandomness\n\nlibrary(DescTools)\nr <- RunsTest(row1$y1)\n\n\n\n4.2.2 Doublets\nThe doublets test. Description.\nLet’s manually produce a code to execute the doublets test. To facilitate, we can create a function and name it doublets.test. The only argument needed is the vector of binary data.\n\ndoublets.test <- function(x) {\n# Identify the sequence\nS <- x\n# Compute the number of doublets Db\nmatrix <- cbind(S[-length(S)], S[-1])\npairs <- table(data.frame(matrix))\nDb <- pairs[2,2]\n# Count the number of diseased plants\nN <- length(S) \n# Count the number of total plants\nm = sum(S) \n# Expected number of doublets\nEDb = m *((m -1)/N)\n# Standard deviation \nSDb = sqrt ( EDb * (1 - (2 / N)))\n# Calculate the Z-value \nZDb = (Db - EDb)/ SDb \n# two-sided P-value calculation\npvalue <- (2*pnorm(abs(ZDb), lower.tail = FALSE))\n# Result of the test\nresult <- ifelse(abs(ZDb) >= 1.64, \nc(\"aggregation or clustering\"), \nc(\"randomness\")) \n# Print the results\nprint(paste(\"There are\",Db,\"doublets. The number of expected doublets is\",EDb,\".\",\"P-value:\", round(pvalue,4), \". Alternative hypothesis: non-randomness\"))\n}\n\n\n# Run the function calling the vector\ndoublets.test(row1$y1)\n\n[1] \"There are 4 doublets. The number of expected doublets is 2.8 . P-value: 0.4497 . Alternative hypothesis: non-randomness\"\n\n\n\n\n4.2.3 Join count\nJoin count statistics. Description.\nLet’s use the join.count function of the spdep package to perform a joint count test. First we need to create the series of binary data from left to right. In the example, there are 5 rows and 5 colums. This will be informed later to run the test.\n\n# Enter the data\nS2 <- c(1,1,1,1,0,\n       0,1,0,0,1,\n       1,0,1,0,0,\n       1,0,0,1,1,\n       0,0,0,0,1)\n\nVisualize the grid\n\n# Convert to raster \nmapS2 <- raster::raster(matrix(S2, 5 ,5))\n\n# Convert to data frame\nmapS3 <- raster::as.data.frame(mapS2,xy=TRUE)\n\n# Map using ggplot\nmapS3 %>% \n  ggplot(aes(x, y, label = layer, fill = factor(layer)))+\n  geom_tile(color = \"black\")+\n  theme_void()+\n  geom_text()+\n  scale_fill_manual(values = c(\"green\", \"red\"))\n\n\n\n\nLoad the library\n\nlibrary(spdep)\n\nFirst, we need to generate a list of neighbors (nb) for a grid of cells. This is performed with the cell2nb function by informing the number of rows and columns. The argument “rook” means shared edge, but it could be the “queen”, for shared edge or vertex. We can use the default.\n\nnb <- cell2nb(nrow = 5, \n              ncol = 5, \n              type=\"rook\")\n\nThe joincount.test function runs the BB join count test for spatial autocorrelation. From the function description, the method uses a spatial weights matrix in weights list form for testing whether same-status joins occur more frequently than would be expected if the zones were labelled in a spatially random way. We need to inform the sequence as factor and the nb object we created previously.\n\njoincount.test(factor(S2), \n                nb2listw(nb))\n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb) \n\nStd. deviate for 0 = -0.58266, p-value = 0.7199\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            2.9583333             3.2500000             0.2505797 \n\n\n    Join count test under nonfree sampling\n\ndata:  factor(S2) \nweights: nb2listw(nb) \n\nStd. deviate for 1 = -0.66841, p-value = 0.7481\nalternative hypothesis: greater\nsample estimates:\nSame colour statistic           Expectation              Variance \n            2.4166667             2.7500000             0.2486957 \n\n\nThe function returns a list with a class for each of the status (in this case 0 and 1) with several components. We should look at the P-value. The alternative hypothesis (greater) is that the same status joins occur more frequently than expected if they were labelled in a spatial random way. In this case, we do not reject the null hypothesis of randomness.\nWe can run the ordinary runs and doublets tests, which only considers the adjacent neighbor, for the same series and compare the results.\n\noruns.test(S2)\n\n[1] \"There are 13 runs. The number of expected runs is 13.5 P-value: 0.844252 . Alternative hypothesis: non-randomness\"\n\ndoublets.test(S2)\n\n[1] \"There are 5 doublets. The number of expected doublets is 5.28 . P-value: 0.8989 . Alternative hypothesis: non-randomness\"\n\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F., eds. 2017. CHAPTER 9: Spatial aspects of epidemicsIII: Patterns of plant disease. In The American Phytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009."
  },
  {
    "objectID": "spatial-patterns.html#real-examples",
    "href": "spatial-patterns.html#real-examples",
    "title": "4  Spatial patterns",
    "section": "4.3 Real examples",
    "text": "4.3 Real examples\n\nlibrary(epiphy)\n\n\nAttaching package: 'epiphy'\n\n\nThe following object is masked from 'package:dplyr':\n\n    count\n\n\nThe following object is masked from 'package:stats':\n\n    chisq.test\n\nseries <- citrus_ctv$IVI3and4 %>% \n  filter(t == 1991) %>% \n  pull(i)\n\noruns.test(series)\n\n[1] \"There are 54 runs. The number of expected runs is 71.1 P-value: 0.00032 . Alternative hypothesis: non-randomness\"\n\nruns.test(series, threshold = 0.5)\n\n\n    Runs Test\n\ndata:  series\nstatistic = -3.5985, runs = 54, n1 = 44, n2 = 172, n = 216, p-value =\n0.0003201\nalternative hypothesis: nonrandomness\n\ndoublets.test(series)\n\n[1] \"There are 17 doublets. The number of expected doublets is 8.75925925925926 . P-value: 0.0052 . Alternative hypothesis: non-randomness\"\n\n\n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F., eds. 2017. CHAPTER 9: Spatial aspects of epidemicsIII: Patterns of plant disease. In The American Phytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Madden, L. V., Hughes, G., and Bosch, F. van den. 2017a. The study of\nplant disease epidemics. Available at: http://dx.doi.org/10.1094/9780890545058.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F., eds. 2017b. CHAPTER 4:\nTemporal analysis i: Quantifying and comparing epidemics. In The\nAmerican Phytopathological Society, p. 63–116. Available at: http://dx.doi.org/10.1094/9780890545058.004.\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F., eds. 2017c. CHAPTER 9:\nSpatial aspects of epidemicsIII: Patterns of plant disease.\nIn The American Phytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009."
  },
  {
    "objectID": "spatial-patterns.html#section",
    "href": "spatial-patterns.html#section",
    "title": "4  Spatial patterns",
    "section": "4.3 ",
    "text": "4.3 \n\n\n\n\n\nMadden, L. V., Hughes, G., and van den Bosch, F., eds. 2017. CHAPTER 9: Spatial aspects of epidemicsIII: Patterns of plant disease. In The American Phytopathological Society, p. 235–278. Available at: http://dx.doi.org/10.1094/9780890545058.009."
  }
]